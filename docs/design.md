# ğŸ§© Software Design â€“ TorqueTalk

## ğŸ“ Folder Structure

---

torquetalk/
â”œâ”€â”€ app/
â”‚ â”œâ”€â”€ chat_ui.py
â”‚ â””â”€â”€ rag_pipeline.py
â”œâ”€â”€ data/ 
â”œâ”€â”€ models/
â”œâ”€â”€ scripts/
â”‚ â”œâ”€â”€ parse_obd_logs.py
â”‚ â”œâ”€â”€ extract_faults.py
â”œâ”€â”€ faiss_index/
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md



---

## ğŸ§  Core Modules

### 1. `chat_ui.py`
- Renders chatbot in Streamlit
- Sends query to LangChain interface
- Displays answer from Ollama

### 2. `rag_pipeline.py`
- Loads vector DB (FAISS)
- Performs similarity search for relevant docs
- Constructs prompt with retrieved context
- Sends to Ollama and returns response

### 3. `parse_obd_logs.py`
- Accepts raw logs from diagnostic tools
- Extracts fault codes, timestamps, descriptions
- Converts to structured JSON for vector indexing

### 4. `extract_faults.py`
- Parses PDF/DOCX service manuals
- Extracts fault-related sections
- Stores text chunks and metadata

---

## ğŸ”„ Data Flow

1. ğŸ§¾ User uploads an OBD log or asks a question
2. ğŸ§  LangChain RAG pipeline:
   - Vector search from FAISS using query embedding
   - Constructs a prompt with top-K relevant chunks
3. ğŸ¤– Ollama responds using local LLaMA2
4. ğŸ’¬ Response displayed in Streamlit chat interface

---

## ğŸ›  Technologies Used

| Component      | Technology        |
|----------------|-------------------|
| UI             | Streamlit         |
| Orchestration  | LangChain         |
| Vector DB      | FAISS             |
| LLM Runtime    | Ollama (LLaMA2)   |
| File Parsing   | PyMuPDF, `docx`, custom parsers |

---

_Last updated: 2025-06-06_
